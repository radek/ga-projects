{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solar\n",
    "\n",
    "Project Solar is an attempt to equire information about sourounding envrionment in a living space, analize it, and build predictions in order to answer:\n",
    "\n",
    "> Determine value of artificial light to counteract its natural deficit\n",
    "\n",
    "+ Given time of the day, provide an answer about the level of light\n",
    "+ Given time of the day (and day of the week) - provide an answer if light should be on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['motion', 'light_scaled', 'sound_scaled', 'location_black',\n",
       "       'location_blue', 'location_green', 'location_orange', 'location_purple',\n",
       "       'sun_evening', 'sun_morning', 'sun_night', 'sun_noon', 'sun_sunrise',\n",
       "       'sun_sunset', 'dot_week', 'sound_log_scaled', 'light_log_scaled'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('data/sensing_numeric.pkl')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding classification feature (predictable benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    373632.000000\n",
       "mean          3.119393\n",
       "std           2.613058\n",
       "min           0.000000\n",
       "25%           0.803937\n",
       "50%           1.984868\n",
       "75%           6.535657\n",
       "max           9.339017\n",
       "Name: light_log_scaled, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['light_log_scaled'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate 25 percentile of light at each location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_light_percentile(dataframe, q):\n",
    "    light_log_scaled_percentile = lambda x: np.percentile(x, q = q)\n",
    "    \n",
    "    light_daily_banchmark = dataframe.groupby([\n",
    "        dataframe.index.get_level_values('timestamp').day,\n",
    "        'location_black', \n",
    "        'location_blue', \n",
    "        'location_green', \n",
    "        'location_orange', \n",
    "        'location_purple']).agg({\n",
    "            'light_log_scaled': light_log_scaled_percentile\n",
    "        }).rename(columns={'light_log_scaled': 'light_log_scaled_percentile_{}'.format(q)})\n",
    "    return light_daily_banchmark\n",
    "\n",
    "daily_light_percentile_25 = get_daily_light_percentile(df, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add percentile to data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_quantile(dataframe):\n",
    "    location_indexer = [\n",
    "        'location_black', \n",
    "        'location_blue', \n",
    "        'location_green', \n",
    "        'location_orange', \n",
    "        'location_purple'\n",
    "    ]\n",
    "\n",
    "    for time in dataframe.index.get_level_values('timestamp').unique():\n",
    "        day_group = dataframe.xs(time, level='timestamp', axis=0)\n",
    "        for location_name in location_indexer:\n",
    "            percentile = day_group.xs(1, level=location_name)['light_log_scaled_percentile_25']\n",
    "            df.loc[((df.index.day == time) & (df[location_name] == 1)), 'daily_light_percentile_25'] = percentile.values[0] if len(percentile.values) else 0\n",
    "        \n",
    "add_quantile(daily_light_percentile_25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hourly motion deviation per day of the week at each location "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_hourly_banchmark = df.groupby([\n",
    "    df.index.get_level_values('timestamp').hour,\n",
    "    'dot_week',\n",
    "    'location_black', \n",
    "    'location_blue', \n",
    "    'location_green', \n",
    "    'location_orange', \n",
    "    'location_purple']).agg({'motion': ['sum', 'std']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_motion_std(dataframe):\n",
    "    location_indexer = [\n",
    "        'location_black', \n",
    "        'location_blue', \n",
    "        'location_green', \n",
    "        'location_orange', \n",
    "        'location_purple'\n",
    "    ]\n",
    "\n",
    "    for time in dataframe.index.get_level_values('timestamp').unique():\n",
    "        day_hour_group = dataframe.xs(time, level='timestamp', axis=0)\n",
    "        for dotw in day_hour_group.index.get_level_values('dot_week').unique():\n",
    "            day_group = day_hour_group.xs(dotw, level='dot_week', axis=0)\n",
    "            for location_name in location_indexer:\n",
    "                std_dev = day_group.xs(1, level=location_name)['motion']['std']\n",
    "                df.loc[((df.index.day == time) & (df['dot_week'] == dotw) & (df[location_name] == 1)), 'daily_motion_std_dev'] = std_dev.values[0] if len(std_dev.values) else 0\n",
    "        \n",
    "add_motion_std(motion_hourly_banchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MINIMUM_DAILY_HOUR_MOTION_DEVIATION = .15\n",
    "\n",
    "def get_light_expected(row):\n",
    "    return 1 if ((row['daily_motion_std_dev'] > MINIMUM_DAILY_HOUR_MOTION_DEVIATION) &\n",
    "        (row['light_log_scaled'] < row['daily_light_percentile_25'])) else 0\n",
    "\n",
    "df['light_expected'] = df.apply(get_light_expected, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 373632 entries, 2018-05-01 01:09:00 to 2018-05-11 23:29:00\n",
      "Data columns (total 20 columns):\n",
      "motion                       373632 non-null int64\n",
      "light_scaled                 373632 non-null float64\n",
      "sound_scaled                 373632 non-null float64\n",
      "location_black               373632 non-null uint8\n",
      "location_blue                373632 non-null uint8\n",
      "location_green               373632 non-null uint8\n",
      "location_orange              373632 non-null uint8\n",
      "location_purple              373632 non-null uint8\n",
      "sun_evening                  373632 non-null uint8\n",
      "sun_morning                  373632 non-null uint8\n",
      "sun_night                    373632 non-null uint8\n",
      "sun_noon                     373632 non-null uint8\n",
      "sun_sunrise                  373632 non-null uint8\n",
      "sun_sunset                   373632 non-null uint8\n",
      "dot_week                     373632 non-null int64\n",
      "sound_log_scaled             373632 non-null float64\n",
      "light_log_scaled             373632 non-null float64\n",
      "daily_light_percentile_25    373632 non-null float64\n",
      "daily_motion_std_dev         373632 non-null float64\n",
      "light_expected               373632 non-null int64\n",
      "dtypes: float64(6), int64(3), uint8(11)\n",
      "memory usage: 42.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature selection (including sensing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['light_expected']\n",
    "X = df[[\n",
    "    'motion',\n",
    "    'light_log_scaled', \n",
    "    'sound_log_scaled', \n",
    "    'location_black', \n",
    "    'location_blue', \n",
    "    'location_green', \n",
    "    'location_orange', \n",
    "    'location_purple', \n",
    "    'sun_evening', \n",
    "    'sun_morning', \n",
    "    'sun_night', \n",
    "    'sun_noon', \n",
    "    'sun_sunrise', \n",
    "    'sun_sunset',\n",
    "    'dot_week']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from helpers import print_predict_scores\n",
    "from helpers import fit_predict\n",
    "logReg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-values:\n",
      "[  3.36373750e-135   0.00000000e+000   5.02931700e-050   1.11887020e-116\n",
      "   2.51581127e-147   0.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "   1.61331000e-185   0.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "   6.87339696e-209   9.08480429e-082   0.00000000e+000]\n",
      "\n",
      "coefficients:\n",
      "[[-0.12354448 -1.27128969  1.0061933   2.06246922  0.37854194 -2.50466148\n",
      "   0.13207178  0.47877156 -1.50853732 -0.97097978 -1.10801083  0.66569838\n",
      "  -0.7275598  -1.83053609 -0.19143677]]\n",
      "\n",
      "intercept: [ 0.54719303]\n",
      "\n",
      "score: 0.8920970366563892\n",
      "\n",
      "mean square root: 0.3284858647546509\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(model, prediction) = fit_predict(X_train, y_train, logReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_error:\n",
      "0.10790296334361082\n",
      "\n",
      "precision_score:\n",
      "0.6917362594678579\n",
      "\n",
      "recall_score:\n",
      "0.3735938114592894\n",
      "\n",
      "classification_report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94    242089\n",
      "          1       0.69      0.37      0.49     38135\n",
      "\n",
      "avg / total       0.88      0.89      0.88    280224\n",
      "\n",
      "\n",
      "mean square root: 0.3284858647546509\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_predict_scores(y_train, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score r2: 0.89391700925\n"
     ]
    }
   ],
   "source": [
    "print('Test score r2:', logReg.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stochastic Gradient Descent classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd = SGDClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-values:\n",
      "[  3.36373750e-135   0.00000000e+000   5.02931700e-050   1.11887020e-116\n",
      "   2.51581127e-147   0.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "   1.61331000e-185   0.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "   6.87339696e-209   9.08480429e-082   0.00000000e+000]\n",
      "\n",
      "coefficients:\n",
      "[[-0.12354448 -1.27128969  1.0061933   2.06246922  0.37854194 -2.50466148\n",
      "   0.13207178  0.47877156 -1.50853732 -0.97097978 -1.10801083  0.66569838\n",
      "  -0.7275598  -1.83053609 -0.19143677]]\n",
      "\n",
      "intercept: [ 0.54719303]\n",
      "\n",
      "score: 0.8920970366563892\n",
      "\n",
      "mean square root: 0.3284858647546509\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(model, prediction) = fit_predict(X_train, y_train, logReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_error:\n",
      "0.10790296334361082\n",
      "\n",
      "precision_score:\n",
      "0.6917362594678579\n",
      "\n",
      "recall_score:\n",
      "0.3735938114592894\n",
      "\n",
      "classification_report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94    242089\n",
      "          1       0.69      0.37      0.49     38135\n",
      "\n",
      "avg / total       0.88      0.89      0.88    280224\n",
      "\n",
      "\n",
      "mean square root: 0.3284858647546509\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_predict_scores(y_train, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.89391700925\n"
     ]
    }
   ],
   "source": [
    "print('Test score:', model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters optimization - cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'C': [10**-i for i in range(-5, 5)], 'class_weight': [None, 'balanced']}\n",
    "]\n",
    "grid = GridSearchCV(\n",
    "    estimator=logReg,\n",
    "    param_grid=param_grid,\n",
    "    cv=7,\n",
    "    scoring = 'neg_mean_squared_error'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)\n",
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-values:\n",
      "[  3.36373750e-135   0.00000000e+000   5.02931700e-050   1.11887020e-116\n",
      "   2.51581127e-147   0.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "   1.61331000e-185   0.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "   6.87339696e-209   9.08480429e-082   0.00000000e+000]\n",
      "\n",
      "coefficients:\n",
      "[[-0.12354448 -1.27128969  1.0061933   2.06246922  0.37854194 -2.50466148\n",
      "   0.13207178  0.47877156 -1.50853732 -0.97097978 -1.10801083  0.66569838\n",
      "  -0.7275598  -1.83053609 -0.19143677]]\n",
      "\n",
      "intercept: [ 0.54719303]\n",
      "\n",
      "score: 0.8920970366563892\n",
      "\n",
      "mean square root: 0.3284858647546509\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(model, prediction) = fit_predict(X_train, y_train, grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_error:\n",
      "0.10790296334361082\n",
      "\n",
      "precision_score:\n",
      "0.6917362594678579\n",
      "\n",
      "recall_score:\n",
      "0.3735938114592894\n",
      "\n",
      "classification_report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.97      0.94    242089\n",
      "          1       0.69      0.37      0.49     38135\n",
      "\n",
      "avg / total       0.88      0.89      0.88    280224\n",
      "\n",
      "\n",
      "mean square root: 0.3284858647546509\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_predict_scores(y_train, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score r2: 0.89391700925\n"
     ]
    }
   ],
   "source": [
    "print('Test score r2:', model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Lasso, Ridge, ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'alpha': [0.1, 0.2, 0.3, 0.5]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = [\n",
    "    {'alpha': [0.1, 0.2, 0.3, 0.5]}\n",
    "]\n",
    "lasso = Lasso()\n",
    "grid_search_lasso = GridSearchCV(lasso, params, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search_lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_lasso.best_estimator_\n",
    "lasso_model = grid_search_lasso.best_estimator_\n",
    "lasso_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean square root error :\n",
      "0.3302167456607731\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction2 = lasso_model.predict(X_train)\n",
    "mse2 = mean_squared_error(prediction2, y_train)\n",
    "print('mean square root error :\\n{}\\n'.format(np.sqrt(mse2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score r2: 0.0686572129826\n",
      "Test score r2: 0.0693025889915\n"
     ]
    }
   ],
   "source": [
    "print('Train score r2:', lasso_model.score(X_train,y_train))\n",
    "print('Test score r2:', lasso_model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'alpha': [0.1, 0.2, 0.3, 0.5]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = Ridge()\n",
    "grid_seaerch_ridge = GridSearchCV(ridge, params, cv = 3, scoring='neg_mean_squared_error')\n",
    "grid_seaerch_ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0.5, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_seaerch_ridge.best_score_\n",
    "ridge_model = grid_seaerch_ridge.best_estimator_\n",
    "ridge_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "square root:\n",
      "0.299346314449808\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction3 = ridge_model.predict(X_train)\n",
    "mse3 = mean_squared_error(prediction3, y_train)\n",
    "print('square root:\\n{}\\n'.format(np.sqrt(mse3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score r2: 0.234651561786\n",
      "Test score r2: 0.238879212989\n"
     ]
    }
   ],
   "source": [
    "print('Train score r2:', ridge_model.score(X_train,y_train))\n",
    "print('Test score r2:', ridge_model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'alpha': [0.1, 0.2, 0.3, 0.5]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en = ElasticNet()\n",
    "grid_seaerch_en = GridSearchCV(en, params, cv = 3, scoring='neg_mean_squared_error')\n",
    "grid_seaerch_en.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=0.1, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_seaerch_en.best_score_\n",
    "en_model = grid_seaerch_en.best_estimator_\n",
    "en_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "square root:\n",
      "0.3277927369762515\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction4 = en_model.predict(X_train)\n",
    "mse4 = mean_squared_error(prediction4, y_train)\n",
    "print('square root:\\n{}\\n'.format(np.sqrt(mse4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score r2: 0.0822803678317\n",
      "Test score r2: 0.0835774566158\n"
     ]
    }
   ],
   "source": [
    "print('Train score r2:', en_model.score(X_train,y_train))\n",
    "print('Test score r2:', en_model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['motion', 'light_scaled', 'sound_scaled', 'location_black',\n",
       "       'location_blue', 'location_green', 'location_orange', 'location_purple',\n",
       "       'sun_evening', 'sun_morning', 'sun_night', 'sun_noon', 'sun_sunrise',\n",
       "       'sun_sunset', 'dot_week', 'sound_log_scaled', 'light_log_scaled',\n",
       "       'daily_light_percentile_25', 'daily_motion_std_dev', 'light_expected'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "knn = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction5 = knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_error:\n",
      "0.0012525693730729701\n",
      "\n",
      "precision_score:\n",
      "0.9958325640281698\n",
      "\n",
      "recall_score:\n",
      "0.9949140929693264\n",
      "\n",
      "classification_report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00    242276\n",
      "          1       1.00      0.99      1.00     37948\n",
      "\n",
      "avg / total       1.00      1.00      1.00    280224\n",
      "\n",
      "\n",
      "mean square root: 0.03539165682859408\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_predict_scores(y_train, prediction5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[242118    158]\n",
      " [   193  37755]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, prediction5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score r2: 0.998747430627\n",
      "Test score r2: 0.997537684138\n"
     ]
    }
   ],
   "source": [
    "print('Train score r2:', knn.score(X_train,y_train))\n",
    "print('Test score r2:', knn.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cross_val_predict(knn, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[241899,    377],\n",
       "       [   443,  37505]])"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mx = confusion_matrix(y_train, y_pred)\n",
    "conf_mx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression models:\n",
    "    - linear support regressor\n",
    "    - linear vs non-linear kernel\n",
    "    - random forest\n",
    "    - XG Boost model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras - Python library for LSTMs modeling\n",
    "- PyTorch\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
