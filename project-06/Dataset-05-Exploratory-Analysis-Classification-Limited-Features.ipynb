{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solar\n",
    "\n",
    "Project Solar is an attempt to equire information about sourounding envrionment in a living space, analize it, and build predictions in order to answer:\n",
    "\n",
    "> Determine value of artificial light to counteract its natural deficit\n",
    "\n",
    "+ Given time of the day, provide an answer about the level of light\n",
    "+ Given time of the day (and day of the week) - provide an answer if light should be on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['motion', 'light_scaled', 'sound_scaled', 'location_black',\n",
       "       'location_blue', 'location_green', 'location_orange', 'location_purple',\n",
       "       'sun_evening', 'sun_morning', 'sun_night', 'sun_noon', 'sun_sunrise',\n",
       "       'sun_sunset', 'dot_week', 'sound_log_scaled', 'light_log_scaled'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('data/sensing_numeric.pkl')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding classification feature (predictable benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    373632.000000\n",
       "mean          3.119393\n",
       "std           2.613058\n",
       "min           0.000000\n",
       "25%           0.803937\n",
       "50%           1.984868\n",
       "75%           6.535657\n",
       "max           9.339017\n",
       "Name: light_log_scaled, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['light_log_scaled'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate 25 percentile of light in each location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_light_percentile(dataframe, q):\n",
    "    light_log_scaled_percentile = lambda x: np.percentile(x, q = q)\n",
    "    \n",
    "    light_daily_banchmark = dataframe.groupby([\n",
    "        dataframe.index.get_level_values('timestamp').day,\n",
    "        'location_black', \n",
    "        'location_blue', \n",
    "        'location_green', \n",
    "        'location_orange', \n",
    "        'location_purple']).agg({\n",
    "            'light_log_scaled': light_log_scaled_percentile\n",
    "        }).rename(columns={'light_log_scaled': 'light_log_scaled_percentile_{}'.format(q)})\n",
    "    return light_daily_banchmark\n",
    "\n",
    "daily_light_percentile_25 = get_daily_light_percentile(df, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add percentile to data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_quantile(dataframe):\n",
    "    location_indexer = [\n",
    "        'location_black', \n",
    "        'location_blue', \n",
    "        'location_green', \n",
    "        'location_orange', \n",
    "        'location_purple'\n",
    "    ]\n",
    "\n",
    "    for time in dataframe.index.get_level_values('timestamp').unique():\n",
    "        day_group = dataframe.xs(time, level='timestamp', axis=0)\n",
    "        for location_name in location_indexer:\n",
    "            percentile = day_group.xs(1, level=location_name)['light_log_scaled_percentile_25']\n",
    "            df.loc[((df.index.day == time) & (df[location_name] == 1)), 'daily_light_percentile_25'] = percentile.values[0] if len(percentile.values) else 0\n",
    "        \n",
    "add_quantile(daily_light_percentile_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_hourly_banchmark = df.groupby([\n",
    "    df.index.get_level_values('timestamp').hour,\n",
    "    'dot_week',\n",
    "    'location_black', \n",
    "    'location_blue', \n",
    "    'location_green', \n",
    "    'location_orange', \n",
    "    'location_purple']).agg({'motion': ['sum', 'std']})\n",
    "#motion_hourly_banchmark\n",
    "#std-deviation 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_motion_std(dataframe):\n",
    "    location_indexer = [\n",
    "        'location_black', \n",
    "        'location_blue', \n",
    "        'location_green', \n",
    "        'location_orange', \n",
    "        'location_purple'\n",
    "    ]\n",
    "\n",
    "    for time in dataframe.index.get_level_values('timestamp').unique():\n",
    "        day_hour_group = dataframe.xs(time, level='timestamp', axis=0)\n",
    "        for dotw in day_hour_group.index.get_level_values('dot_week').unique():\n",
    "            day_group = day_hour_group.xs(dotw, level='dot_week', axis=0)\n",
    "            for location_name in location_indexer:\n",
    "                std_dev = day_group.xs(1, level=location_name)['motion']['std']\n",
    "                df.loc[((df.index.day == time) & (df['dot_week'] == dotw) & (df[location_name] == 1)), 'daily_motion_std_dev'] = std_dev.values[0] if len(std_dev.values) else 0\n",
    "        \n",
    "add_motion_std(motion_hourly_banchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 373632 entries, 2018-05-01 01:09:00 to 2018-05-11 23:29:00\n",
      "Data columns (total 19 columns):\n",
      "motion                       373632 non-null int64\n",
      "light_scaled                 373632 non-null float64\n",
      "sound_scaled                 373632 non-null float64\n",
      "location_black               373632 non-null uint8\n",
      "location_blue                373632 non-null uint8\n",
      "location_green               373632 non-null uint8\n",
      "location_orange              373632 non-null uint8\n",
      "location_purple              373632 non-null uint8\n",
      "sun_evening                  373632 non-null uint8\n",
      "sun_morning                  373632 non-null uint8\n",
      "sun_night                    373632 non-null uint8\n",
      "sun_noon                     373632 non-null uint8\n",
      "sun_sunrise                  373632 non-null uint8\n",
      "sun_sunset                   373632 non-null uint8\n",
      "dot_week                     373632 non-null int64\n",
      "sound_log_scaled             373632 non-null float64\n",
      "light_log_scaled             373632 non-null float64\n",
      "daily_light_percentile_25    373632 non-null float64\n",
      "daily_motion_std_dev         373632 non-null float64\n",
      "dtypes: float64(6), int64(2), uint8(11)\n",
      "memory usage: 39.6 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MINIMUM_DAILY_HOUR_MOTION_DEVIATION = .15\n",
    "\n",
    "def get_light_expected(row):\n",
    "    return 1 if ((row['daily_motion_std_dev'] > MINIMUM_DAILY_HOUR_MOTION_DEVIATION) &\n",
    "        (row['light_log_scaled'] < row['daily_light_percentile_25'])) else 0\n",
    "\n",
    "df['light_expected'] = df.apply(get_light_expected, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 373632 entries, 2018-05-01 01:09:00 to 2018-05-11 23:29:00\n",
      "Data columns (total 20 columns):\n",
      "motion                       373632 non-null int64\n",
      "light_scaled                 373632 non-null float64\n",
      "sound_scaled                 373632 non-null float64\n",
      "location_black               373632 non-null uint8\n",
      "location_blue                373632 non-null uint8\n",
      "location_green               373632 non-null uint8\n",
      "location_orange              373632 non-null uint8\n",
      "location_purple              373632 non-null uint8\n",
      "sun_evening                  373632 non-null uint8\n",
      "sun_morning                  373632 non-null uint8\n",
      "sun_night                    373632 non-null uint8\n",
      "sun_noon                     373632 non-null uint8\n",
      "sun_sunrise                  373632 non-null uint8\n",
      "sun_sunset                   373632 non-null uint8\n",
      "dot_week                     373632 non-null int64\n",
      "sound_log_scaled             373632 non-null float64\n",
      "light_log_scaled             373632 non-null float64\n",
      "daily_light_percentile_25    373632 non-null float64\n",
      "daily_motion_std_dev         373632 non-null float64\n",
      "light_expected               373632 non-null int64\n",
      "dtypes: float64(6), int64(3), uint8(11)\n",
      "memory usage: 42.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature selection (including sensing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['light_expected']\n",
    "X = df[[\n",
    "    'location_black', \n",
    "    'location_blue', \n",
    "    'location_green', \n",
    "    'location_orange', \n",
    "    'location_purple', \n",
    "    'sun_evening', \n",
    "    'sun_morning', \n",
    "    'sun_night', \n",
    "    'sun_noon', \n",
    "    'sun_sunrise', \n",
    "    'sun_sunset',\n",
    "    'dot_week']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from helpers import print_predict_scores\n",
    "logReg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logReg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_error:\n",
      "0.12764074454721935\n",
      "\n",
      "precision_score:\n",
      "0.5846759224886777\n",
      "\n",
      "recall_score:\n",
      "0.20696995978869354\n",
      "\n",
      "classification_report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.98      0.93    242175\n",
      "          1       0.58      0.21      0.31     38049\n",
      "\n",
      "avg / total       0.85      0.87      0.84    280224\n",
      "\n",
      "\n",
      "mean square root: 0.35726844885494624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = logReg.predict(X_train)\n",
    "print_predict_scores(y_train, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score r2: 0.872359255453\n",
      "Test score r2: 0.872869561494\n"
     ]
    }
   ],
   "source": [
    "print('Train score r2:', logReg.score(X_train,y_train))\n",
    "print('Test score r2:', logReg.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stochastic Gradient Descent classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd = SGDClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/radek.czarnecki/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_error:\n",
      "0.13578066118533744\n",
      "\n",
      "precision_score:\n",
      "0.0\n",
      "\n",
      "recall_score:\n",
      "0.0\n",
      "\n",
      "classification_report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.93    242175\n",
      "          1       0.00      0.00      0.00     38049\n",
      "\n",
      "avg / total       0.75      0.86      0.80    280224\n",
      "\n",
      "\n",
      "mean square root: 0.3684842753569512\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/radek.czarnecki/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/radek.czarnecki/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "prediction = sgd.predict(X_train)\n",
    "print_predict_scores(y_train, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score r2: 0.864219338815\n",
      "Test score r2: 0.864668979102\n"
     ]
    }
   ],
   "source": [
    "print('Train score r2:', sgd.score(X_train,y_train))\n",
    "print('Test score r2:', sgd.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters optimization - cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'C': [10**-i for i in range(-5, 5)], 'class_weight': [None, 'balanced']}\n",
    "]\n",
    "grid = GridSearchCV(\n",
    "    estimator=logReg,\n",
    "    param_grid=param_grid,\n",
    "    cv=7,\n",
    "    scoring = 'neg_mean_squared_error'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_test, y_test)\n",
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_error:\n",
      "0.12559952038369304\n",
      "\n",
      "precision_score:\n",
      "0.6398940864960282\n",
      "\n",
      "recall_score:\n",
      "0.1714893952534889\n",
      "\n",
      "classification_report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.98      0.93    242175\n",
      "          1       0.64      0.17      0.27     38049\n",
      "\n",
      "avg / total       0.85      0.87      0.84    280224\n",
      "\n",
      "\n",
      "mean square root: 0.3544002262748897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = grid.best_estimator_.predict(X_train)\n",
    "print_predict_scores(y_train, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score r2: 0.874400479616\n",
      "Test score r2: 0.875203408702\n"
     ]
    }
   ],
   "source": [
    "print('Train score r2:', grid.best_estimator_.score(X_train,y_train))\n",
    "print('Test score r2:', grid.best_estimator_.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[238503   3672]\n",
      " [ 31524   6525]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Lasso, Ridge, ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'alpha': [0.1, 0.2, 0.3, 0.5]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = [\n",
    "    {'alpha': [0.1, 0.2, 0.3, 0.5]}\n",
    "]\n",
    "lasso = Lasso()\n",
    "grid_search_lasso = GridSearchCV(lasso, params, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search_lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_lasso.best_estimator_\n",
    "lasso_model = grid_search_lasso.best_estimator_\n",
    "lasso_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean square root error :\n",
      "0.3425555038725988\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction2 = lasso_model.predict(X_train)\n",
    "mse2 = mean_squared_error(prediction2, y_train)\n",
    "print('mean square root error :\\n{}\\n'.format(np.sqrt(mse2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score r2: 0.0\n",
      "Test score r2: -1.72775913421e-06\n"
     ]
    }
   ],
   "source": [
    "print('Train score r2:', lasso_model.score(X_train,y_train))\n",
    "print('Test score r2:', lasso_model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'alpha': [0.1, 0.2, 0.3, 0.5]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = Ridge()\n",
    "grid_seaerch_ridge = GridSearchCV(ridge, params, cv = 3, scoring='neg_mean_squared_error')\n",
    "grid_seaerch_ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0.5, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_seaerch_ridge.best_score_\n",
    "ridge_model = grid_seaerch_ridge.best_estimator_\n",
    "ridge_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "square root:\n",
      "0.31125037835633296\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction3 = ridge_model.predict(X_train)\n",
    "mse3 = mean_squared_error(prediction3, y_train)\n",
    "print('square root:\\n{}\\n'.format(np.sqrt(mse3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score r2: 0.174422446383\n",
      "Test score r2: 0.174813348696\n"
     ]
    }
   ],
   "source": [
    "print('Train score r2:', ridge_model.score(X_train,y_train))\n",
    "print('Test score r2:', ridge_model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'alpha': [0.1, 0.2, 0.3, 0.5]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en = ElasticNet()\n",
    "grid_seaerch_en = GridSearchCV(en, params, cv = 3, scoring='neg_mean_squared_error')\n",
    "grid_seaerch_en.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=0.1, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_seaerch_en.best_score_\n",
    "en_model = grid_seaerch_en.best_estimator_\n",
    "en_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "square root:\n",
      "0.3415930880867029\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction4 = en_model.predict(X_train)\n",
    "mse4 = mean_squared_error(prediction4, y_train)\n",
    "print('square root:\\n{}\\n'.format(np.sqrt(mse4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score r2: 0.00561114221135\n",
      "Test score r2: 0.00571305151875\n"
     ]
    }
   ],
   "source": [
    "print('Train score r2:', en_model.score(X_train,y_train))\n",
    "print('Test score r2:', en_model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['motion', 'light_scaled', 'sound_scaled', 'location_black',\n",
       "       'location_blue', 'location_green', 'location_orange', 'location_purple',\n",
       "       'sun_evening', 'sun_morning', 'sun_night', 'sun_noon', 'sun_sunrise',\n",
       "       'sun_sunset', 'dot_week', 'sound_log_scaled', 'light_log_scaled',\n",
       "       'daily_light_percentile_25', 'daily_motion_std_dev', 'light_expected'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "knn = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction5 = knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_squared_error:\n",
      "0.12179542080621217\n",
      "\n",
      "precision_score:\n",
      "0.5514885566387261\n",
      "\n",
      "recall_score:\n",
      "0.5516045099739809\n",
      "\n",
      "classification_report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.93      0.93    242175\n",
      "          1       0.55      0.55      0.55     38049\n",
      "\n",
      "avg / total       0.88      0.88      0.88    280224\n",
      "\n",
      "\n",
      "mean square root: 0.34899200679415593\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_predict_scores(y_train, prediction5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[225106  17069]\n",
      " [ 17061  20988]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, prediction5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score r2: 0.878204579194\n",
      "Test score r2: 0.878158187736\n"
     ]
    }
   ],
   "source": [
    "print('Train score r2:', knn.score(X_train,y_train))\n",
    "print('Test score r2:', knn.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression models:\n",
    "    - linear support regressor\n",
    "    - linear vs non-linear kernel\n",
    "    - random forest\n",
    "    - XG Boost model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras - Python library for LSTMs modeling\n",
    "- PyTorch\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
